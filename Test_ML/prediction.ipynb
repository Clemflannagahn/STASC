{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # supprime certains warnings\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import xgboost as xgb\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def features_incomplete(X):   \n",
    "    Features_incomplete = []\n",
    "    for x in X.columns:\n",
    "        if X[x].isnull().sum()/len(X[x])*100 > 0:\n",
    "            Features_incomplete.append(x)\n",
    "    return Features_incomplete\n",
    "\n",
    "def preprocess(X):\n",
    "    X.drop(columns = [\"exposition\"],inplace=True)\n",
    "    X.drop(columns=['ghg_category', 'energy_performance_category'], inplace=True)\n",
    "    X['floor'].fillna(0, inplace=True)\n",
    "    X['land_size'].fillna(0, inplace=True)\n",
    "\n",
    "    #one hot encoding for property_type\n",
    "    X = pd.get_dummies(X, columns=['property_type'], drop_first=False)\n",
    "\n",
    "    # Label encoding for city\n",
    "    le = LabelEncoder()\n",
    "    X['city'] = le.fit_transform(X['city'])\n",
    "\n",
    "\n",
    "    # Calcul des valeurs des départements plutôt que des codes postaux (en séparant les départements à 4 chiffres des départements à 5 chiffres)\n",
    "    X[\"departement\"]=X[\"postal_code\"]\n",
    "    X[\"departement\"][X[\"departement\"] < 10000]=X[\"departement\"].astype(str).str[:1].astype(int)\n",
    "    X[\"departement\"][X[\"departement\"] >= 10000]=X[\"departement\"].astype(str).str[:2].astype(int)\n",
    "\n",
    "    # Tentatives de remplir les valeurs manquantes de ces colonnes par la valeur moyenne pour le code postal associé\n",
    "    #X[\"POPULATION_x\"].fillna(X.groupby(\"postal_code\")[\"POPULATION_x\"].transform(\"mean\"), inplace=True)\n",
    "    #X[\"Nb_Transac\"].fillna(X.groupby(\"postal_code\")[\"Nb_Transac\"].transform(\"mean\"), inplace=True)\n",
    "    #X[\"Nb_Ventes\"].fillna(X.groupby(\"postal_code\")[\"Nb_Ventes\"].transform(\"mean\"), inplace=True)\n",
    "    \n",
    "    X[\"nearly_price\"]=X[\"PrixMoyen_M2\"]*X[\"size\"]\n",
    "    X[\"nearly_price_1819\"]=X[\"PrixMoyen_M2_1819\"]*X[\"size\"]\n",
    "    X[\"prix_metre\"] = np.sqrt(X[\"PrixMoyen_M2\"])\n",
    "    X[\"prix_metre_1819\"] = np.sqrt(X[\"PrixMoyen_M2_1819\"])\n",
    "    # X[\"prix_metre_2017\"] = np.sqrt(X[\"Prix_2017\"])\n",
    "    # X[\"prix_metre_2018\"] = np.sqrt(X[\"Prix_2018\"])\n",
    "    # X[\"racine_size\"] = np.sqrt(X[\"size\"])\n",
    "    # X[\"racine_land_size\"] = np.sqrt(X[\"land_size\"])\n",
    "    \n",
    "    X[\"Somme_bedrooms_rooms\"] = X[\"nb_rooms\"]+X[\"nb_bedrooms\"]\n",
    "    X[\"Somme_bathrooms_rooms\"] = X[\"nb_rooms\"]+X[\"nb_bathrooms\"]\n",
    "    X[\"Diff_bedrooms_bathrooms\"] = X[\"nb_bathrooms\"]-X[\"nb_bedrooms\"]\n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "    # Prendre l'entier de la longitude et de la latitude\n",
    "    X[\"approximate_longitude\"]=X[\"approximate_longitude\"].astype(int)\n",
    "    X[\"approximate_latitude\"]=X[\"approximate_latitude\"].astype(int)\n",
    "    \n",
    "    \n",
    "    for x in [\"approximate_longitude\",\"approximate_latitude\",\"nearly_price\"]:\n",
    "    # On remplit le reste par la valeur moyenne du département\n",
    "        X[x].fillna(X.groupby(\"departement\")[x].transform(\"mean\"), inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    X = X.drop(columns = [\"id_annonce\"],axis=1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(MinMaxScaler(), KMeans(n_clusters=15),MinMaxScaler(), xgb.XGBRegressor())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:43:44) [Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97c892bb3c077c71a79e73100b36200d50adffbda6aedb9a1044fd256d6aacf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
